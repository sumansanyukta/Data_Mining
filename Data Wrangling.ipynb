{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training file\n",
    "df_train_csv = pd.read_csv('files/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the individual subjects from training set\n",
    "df_train_csv_subjects = list(dict(df_train_csv['Subject'].value_counts()).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [] # To store the dataframes\n",
    "\n",
    "def parse_subject_files(subject,all_files):\n",
    "    '''\n",
    "    Input: Subject in the train file and all the instances(files) of that subject\n",
    "    \n",
    "    1. Loop through all the files(instances) of the subject present the subject folder\n",
    "    2. Validating the subject in the train file.\n",
    "    3. Add the list of dataframes into list_of_dfs\n",
    "    \n",
    "    '''\n",
    "    print(subject,' : started processing.....')\n",
    "    \n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, header=None)\n",
    "        if filename.split(sep='\\\\')[1] in list(df_train_csv['Datafile'].str\n",
    "                                                                      .partition('/')[2]):\n",
    "            current_label = (df_train_csv[df_train_csv['Datafile']==\n",
    "                                          (''.join([subject,'/',filename.split(sep='\\\\')[1]]))]\n",
    "                                          ['Label'].values[0])\n",
    "            df['Label'] = current_label\n",
    "            list_of_dfs.append(df)\n",
    "            \n",
    "    print(subject,' : completed processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject06  : started processing.....\n",
      "Subject06  : completed processing\n",
      "Subject13  : started processing.....\n",
      "Subject13  : completed processing\n",
      "Subject19  : started processing.....\n",
      "Subject19  : completed processing\n",
      "Subject02  : started processing.....\n",
      "Subject02  : completed processing\n",
      "Subject12  : started processing.....\n",
      "Subject12  : completed processing\n",
      "Subject03  : started processing.....\n",
      "Subject03  : completed processing\n",
      "Subject17  : started processing.....\n",
      "Subject17  : completed processing\n",
      "Subject07  : started processing.....\n",
      "Subject07  : completed processing\n",
      "Subject09  : started processing.....\n",
      "Subject09  : completed processing\n",
      "Subject05  : started processing.....\n",
      "Subject05  : completed processing\n",
      "Subject04  : started processing.....\n",
      "Subject04  : completed processing\n",
      "Subject18  : started processing.....\n",
      "Subject18  : completed processing\n",
      "Subject11  : started processing.....\n",
      "Subject11  : completed processing\n",
      "Subject08  : started processing.....\n",
      "Subject08  : completed processing\n",
      "Subject16  : started processing.....\n",
      "Subject16  : completed processing\n"
     ]
    }
   ],
   "source": [
    "# Loop through each subject in the train file and call the parse_subject_files definition\n",
    "for i in range(len(df_train_csv_subjects)):\n",
    "    path = r'/Users/sanyu/OneDrive - Jacobs University/2nd Sem/Data Mining/bbdc2019/files/'+df_train_csv_subjects[i]\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    parse_subject_files(df_train_csv_subjects[i],all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all the files in a single frame\n",
    "df_train_main = pd.concat(list_of_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "# A 'ground truth' column named as Label has been added as our y-variable\n",
    "df_train_main.columns = ['EMG1',\n",
    "                'EMG2',\n",
    "                'EMG3',\n",
    "                'EMG4',\n",
    "                'Airborne',\n",
    "                'ACC upper X',\n",
    "                'ACC upper Y',\n",
    "                'ACC upper Z',\n",
    "                'Goniometer X',\n",
    "                'ACC lower X',\n",
    "                'ACC lower Y',\n",
    "                'ACC loewr Z',\n",
    "                'Goniometer Y',\n",
    "                'Gyro upper X',\n",
    "                'Gyro upper Y',\n",
    "                'Gyro upper Z',\n",
    "                'Gyro lower X',\n",
    "                'Gyro lower Y',\n",
    "                'Gyro lower Z',\n",
    "                'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_train_main['Label'] = label_encoder.fit_transform(df_train_main['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = stats.zscore(df_train_main)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 1).all(axis=1)\n",
    "df_train_main = df_train_main[filtered_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train_main.iloc[:,:-1].values\n",
    "y = df_train_main.iloc[:,19].values\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "onehotencoder = OneHotEncoder(categories='auto')\n",
    "y = onehotencoder.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train-test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20)\n",
    "\n",
    "# Feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 8) #found this to be the optimal number of columns \n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the original dataframe\n",
    "figure(num=None, figsize=(20, 18), dpi=80, facecolor='w', edgecolor='k')\n",
    "#sns.heatmap(df_train_main.corr(), annot=True, fmt=\".2%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# after PCA we found 8 columns which can be selected \n",
    "figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "#sns.heatmap(pd.DataFrame(x_train).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.figure(figsize=(8,8),facecolor='red',edgecolor='blue')\n",
    "#df['N'].hist(by=df['Letter'], figsize = (16,18))\n",
    "df_train_main.groupby('Label').hist(figsize = (8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# filter warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)    \n",
    "knn.fit(x_train, y_train)\n",
    "from sklearn import metrics\n",
    "# predict the response\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "#print(metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# evaluate and return  accuracy return accuracy_score(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(random_state=0)\n",
    "dt = dt.fit(x_train, y_train)\n",
    "tree.plot_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor().fit(x_train, y_train)\n",
    "predicted = dt.predict(x_test)\n",
    "expected = y_test\n",
    "\n",
    "plt.scatter(expected, predicted) \n",
    "\n",
    "plt.plot([0, 50], [0, 50], '--k') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = KNeighborsClassifier()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(cross_val, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_report = classification_report(y_test,predictions,output_dict=True)\n",
    "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
